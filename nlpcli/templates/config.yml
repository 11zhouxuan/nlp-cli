task_type: {{task_type}}
project_name: {{project_name}}
# 数据的存放路径
PathTrain: ''
PathDev: ''
PathTest: ''
# 大的数据集集缓存设置
DataCache:
  # 是否利用缓存数据, 如果设置就可以用下面的地址进行数据初始化
  UseCachedData: False
  CachedPathTrain: '' # 训练集的缓存路径
  CachedPathDev: '' # 验证集缓存路径
  CachedPathTest: '' # 测试集缓存路径
  # 对于缓存数据,如果没那么大就直接加载到内存,这样可以实现shuffle
  # 可选单位 ['B', 'KB', 'MB', 'GB', 'TB', 'PB']
  CachedDataThresholdSize: 100M

  # 是否缓存当前的训练数据, 如果设置成True,那么当前的训练数据送到生成器之前为str形式
  # 如果不指定缓存路径,默认将缓存当在 DataCache 路径下面
  CachingCurrentData: False #
  CachingDirectory: 'DataCache' # 缓存文件夹, 默认在config对应的下面
  MaxCaching: 5 # 最大缓存的文件夹数量,注意每次缓存都会产生一个文件夹,超过最大值会进行对之前的进行删除

TextHeaders:
  text_a: 0 # 列的index从1开始,0 或者False 表示没有这一列
  text_b: 0
  label: 0 # 一般需要这个字段，并且不能改成其他名字
TaskInput:
  TextHasHeaders: True # txt文本是否有表头
  SentencesDelimiter: "\n" # 句子之间的分隔符,特殊字符注意用双引号
  ColumnDelimiter: "\t" # 列之间的分隔符, 特殊字符注意用双引号
  {% if task_type == "sl" -%}
  CharacterDelimiter: "\x02" # 字符之间的分隔符,用于NER等序列标注任务中, 特殊字符注意用双引号
  {% endif %}
  VocabFilePath: '' # 词典对应的地址,如果是pkl格式,会尝试解析为一个字典，否则需要人工编写函数
  LabelMapPath: '' # .json或者.pkl 保存的字典, 默认会用着两种方式进行解析
  FeaturePaddingStrOrInt: '' # padding用什么字符代替,可以是字符或者直接是id

{% if tokenizer_type == "bert" -%}
Bert_config:
  bert_init_checkpoint_dir: ''
{% endif %}
{% if computation_tool == "tensorflow" -%}
TensorflowConfig:
  PathSummary: '' # summary 存放的对应的位置
{% endif %}
# 训练与测试参数
TrainParamaters:
  BatchSize: 16
  TotalStep: 10000
  EvaluateEveryStep: 100 # 多少个step进行打印
EvaluateParameters:
  BatchSize: 50
PredictParameters:
  BatchSize: 50





